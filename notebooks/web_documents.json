[
  {
    "content": "\n\n\n\n\n\n\nstyleguide | Style guides for Google-originated open-source projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstyleguide\n\nGoogle Python Style Guide\n\n\nTable of Contents\n\n1 Background\n2 Python Language Rules\n\n2.1 Lint\n2.2 Imports\n2.3 Packages\n2.4 Exceptions\n2.5 Mutable Global State\n2.6 Nested/Local/Inner Classes and Functions\n2.7 Comprehensions & Generator Expressions\n2.8 Default Iterators and Operators\n2.9 Generators\n2.10 Lambda Functions\n2.11 Conditional Expressions\n2.12 Default Argument Values\n2.13 Properties\n2.14 True/False Evaluations\n2.16 Lexical Scoping\n2.17 Function and Method Decorators\n2.18 Threading\n2.19 Power Features\n2.20 Modern Python: from __future__ imports\n2.21 Type Annotated Code\n\n\n3 Python Style Rules\n\n3.1 Semicolons\n3.2 Line length\n3.3 Parentheses\n3.4 Indentation\n\n3.4.1 Trailing commas in sequences of items?\n\n\n3.5 Blank Lines\n3.6 Whitespace\n3.7 Shebang Line\n3.8 Comments and Docstrings\n\n3.8.1 Docstrings\n3.8.2 Modules\n3.8.2.1 Test modules\n3.8.3 Functions and Methods\n3.8.3.1 Overridden Methods\n3.8.4 Classes\n3.8.5 Block and Inline Comments\n3.8.6 Punctuation, Spelling, and Grammar\n\n\n3.10 Strings\n\n3.10.1 Logging\n3.10.2 Error Messages\n\n\n3.11 Files, Sockets, and similar Stateful Resources\n3.12 TODO Comments\n3.13 Imports formatting\n3.14 Statements\n3.15 Accessors\n3.16 Naming\n\n3.16.1 Names to Avoid\n3.16.2 Naming Conventions\n3.16.3 File Naming\n3.16.4 Guidelines derived from Guido\u2019s Recommendations\n\n\n3.17 Main\n3.18 Function length\n3.19 Type Annotations\n\n3.19.1 General Rules\n3.19.2 Line Breaking\n3.19.3 Forward Declarations\n3.19.4 Default Values\n3.19.5 NoneType\n3.19.6 Type Aliases\n3.19.7 Ignoring Types\n3.19.8 Typing Variables\n3.19.9 Tuples vs Lists\n3.19.10 Type variables\n3.19.11 String types\n3.19.12 Imports For Typing\n3.19.13 Conditional Imports\n3.19.14 Circular Dependencies\n3.19.15 Generics\n3.19.16 Build Dependencies\n\n\n\n\n4 Parting Words\n\n\n\n\n\n1 Background\nPython is the main dynamic language used at Google. This style guide is a list\nof dos and don\u2019ts for Python programs.\nTo help you format code correctly, we\u2019ve created a settings file for Vim. For Emacs, the default settings should be fine.\nMany teams use the Black or Pyink\nauto-formatter to avoid arguing over formatting.\n\n\n\n2 Python Language Rules\n\n\n\n2.1 Lint\nRun pylint over your code using this pylintrc.\n\n\n\n2.1.1 Definition\npylint\nis a tool for finding bugs and style problems in Python source code. It finds\nproblems that are typically caught by a compiler for less dynamic languages like\nC and C++. Because of the dynamic nature of Python, some\nwarnings may be incorrect; however, spurious warnings should be fairly\ninfrequent.\n\n\n\n2.1.2 Pros\nCatches easy-to-miss errors like typos, using-vars-before-assignment, etc.\n\n\n\n2.1.3 Cons\npylint\nisn\u2019t perfect. To take advantage of it, sometimes we\u2019ll need to write around it,\nsuppress its warnings or fix it.\n\n\n\n2.1.4 Decision\nMake sure you run\npylint\non your code.\nSuppress warnings if they are inappropriate so that other issues are not hidden.\nTo suppress warnings, you can set a line-level comment:\ndef do_PUT(self):  # WSGI name, so pylint: disable=invalid-name\n  ...\n\npylint\nwarnings are each identified by symbolic name (empty-docstring)\nGoogle-specific warnings start with g-.\nIf the reason for the suppression is not clear from the symbolic name, add an\nexplanation.\nSuppressing in this way has the advantage that we can easily search for\nsuppressions and revisit them.\nYou can get a list of\npylint\nwarnings by doing:\npylint --list-msgs\n\nTo get more information on a particular message, use:\npylint --help-msg=invalid-name\n\nPrefer pylint: disable to the deprecated older form pylint: disable-msg.\nUnused argument warnings can be suppressed by deleting the variables at the\nbeginning of the function. Always include a comment explaining why you are\ndeleting it. \u201cUnused.\u201d is sufficient. For example:\ndef viking_cafe_order(spam: str, beans: str, eggs: str | None = None) -> str:\n    del beans, eggs  # Unused by vikings.\n    return spam + spam + spam\n\nOther common forms of suppressing this warning include using \u2018_\u2019 as the\nidentifier for the unused argument or prefixing the argument name with\n\u2018unused_\u2019, or assigning them to \u2018_\u2019. These forms are allowed but no longer\nencouraged. These break callers that pass arguments by name and do not enforce\nthat the arguments are actually unused.\n\n\n\n2.2 Imports\nUse import statements for packages and modules only, not for individual types,\nclasses, or functions.\n\n\n\n2.2.1 Definition\nReusability mechanism for sharing code from one module to another.\n\n\n\n2.2.2 Pros\nThe namespace management convention is simple. The source of each identifier is\nindicated in a consistent way; x.Obj says that object Obj is defined in\nmodule x.\n\n\n\n2.2.3 Cons\nModule names can still collide. Some module names are inconveniently long.\n\n\n\n2.2.4 Decision\n\nUse import x for importing packages and modules.\nUse from x import y where x is the package prefix and y is the module\nname with no prefix.\nUse from x import y as z in any of the following circumstances:\n    \nTwo modules named y are to be imported.\ny conflicts with a top-level name defined in the current module.\ny conflicts with a common parameter name that is part of the public\nAPI (e.g., features).\ny is an inconveniently long name.\ny is too generic in the context of your code (e.g., from\nstorage.file_system import options as fs_options).\n\n\nUse import y as z only when z is a standard abbreviation (e.g., import\nnumpy as np).\n\nFor example the module sound.effects.echo may be imported as follows:\nfrom sound.effects import echo\n...\necho.EchoFilter(input, output, delay=0.7, atten=4)\n\nDo not use relative names in imports. Even if the module is in the same package,\nuse the full package name. This helps prevent unintentionally importing a\npackage twice.\n\n2.2.4.1 Exemptions\nExemptions from this rule:\n\nSymbols from the following modules are used to support static analysis and\ntype checking:\n    \ntyping module\ncollections.abc module\ntyping_extensions module\n\n\nRedirects from the\nsix.moves module.\n\n\n\n\n2.3 Packages\nImport each module using the full pathname location of the module.\n\n\n\n2.3.1 Pros\nAvoids conflicts in module names or incorrect imports due to the module search\npath not being what the author expected. Makes it easier to find modules.\n\n\n\n2.3.2 Cons\nMakes it harder to deploy code because you have to replicate the package\nhierarchy. Not really a problem with modern deployment mechanisms.\n\n\n\n2.3.3 Decision\nAll new code should import each module by its full package name.\nImports should be as follows:\nYes:\n  # Reference absl.flags in code with the complete name (verbose).\n  import absl.flags\n  from doctor.who import jodie\n\n  _FOO = absl.flags.DEFINE_string(...)\n\nYes:\n  # Reference flags in code with just the module name (common).\n  from absl import flags\n  from doctor.who import jodie\n\n  _FOO = flags.DEFINE_string(...)\n\n(assume this file lives in doctor/who/ where jodie.py also exists)\nNo:\n  # Unclear what module the author wanted and what will be imported.  The actual\n  # import behavior depends on external factors controlling sys.path.\n  # Which possible jodie module did the author intend to import?\n  import jodie\n\nThe directory the main binary is located in should not be assumed to be in\nsys.path despite that happening in some environments. This being the case,\ncode should assume that import jodie refers to a third-party or top-level\npackage named jodie, not a local jodie.py.\n\n\n\n2.4 Exceptions\nExceptions are allowed but must be used carefully.\n\n\n\n2.4.1 Definition\nExceptions are a means of breaking out of normal control flow to handle errors\nor other exceptional conditions.\n\n\n\n2.4.2 Pros\nThe control flow of normal operation code is not cluttered by error-handling\ncode. It also allows the control flow to skip multiple frames when a certain\ncondition occurs, e.g., returning from N nested functions in one step instead of\nhaving to plumb error codes through.\n\n\n\n2.4.3 Cons\nMay cause the control flow to be confusing. Easy to miss error cases when making\nlibrary calls.\n\n\n\n2.4.4 Decision\nExceptions must follow certain conditions:\n\n\nMake use of built-in exception classes when it makes sense. For example,\nraise a ValueError to indicate a programming mistake like a violated\nprecondition, such as may happen when validating function arguments.\n\n\nDo not use assert statements in place of conditionals or validating\npreconditions. They must not be critical to the application logic. A litmus\ntest would be that the assert could be removed without breaking the code.\nassert conditionals are\nnot guaranteed\nto be evaluated. For pytest based tests, assert is\nokay and expected to verify expectations. For\nexample:\nYes:\n  def connect_to_next_port(self, minimum: int) -> int:\n    \"\"\"Connects to the next available port.\n\n    Args:\n      minimum: A port value greater or equal to 1024.\n\n    Returns:\n      The new minimum port.\n\n    Raises:\n      ConnectionError: If no available port is found.\n    \"\"\"\n    if minimum < 1024:\n      # Note that this raising of ValueError is not mentioned in the doc\n      # string's \"Raises:\" section because it is not appropriate to\n      # guarantee this specific behavioral reaction to API misuse.\n      raise ValueError(f'Min. port must be at least 1024, not {minimum}.')\n    port = self._find_next_open_port(minimum)\n    if port is None:\n      raise ConnectionError(\n          f'Could not connect to service on port {minimum} or higher.')\n    # The code does not depend on the result of this assert.\n    assert port >= minimum, (\n        f'Unexpected port {port} when minimum was {minimum}.')\n    return port\n \nNo:\n  def connect_to_next_port(self, minimum: int) -> int:\n    \"\"\"Connects to the next available port.\n\n    Args:\n      minimum: A port value greater or equal to 1024.\n\n    Returns:\n      The new minimum port.\n    \"\"\"\n    assert minimum >= 1024, 'Minimum port must be at least 1024.'\n    # The following code depends on the previous assert.\n    port = self._find_next_open_port(minimum)\n    assert port is not None\n    # The type checking of the return statement relies on the assert.\n    return port\n \n\n\nLibraries or packages may define their own exceptions. When doing so they\nmust inherit from an existing exception class. Exception names should end in\nError and should not introduce repetition (foo.FooError).\n\n\nNever use catch-all except: statements, or catch Exception or\nStandardError, unless you are\n\nre-raising the exception, or\ncreating an isolation point in the program where exceptions are not\npropagated but are recorded and suppressed instead, such as protecting a\nthread from crashing by guarding its outermost block.\n\nPython is very tolerant in this regard and except: will really catch\neverything including misspelled names, sys.exit() calls, Ctrl+C interrupts,\nunittest failures and all kinds of other exceptions that you simply don\u2019t\nwant to catch.\n\n\nMinimize the amount of code in a try/except block. The larger the body\nof the try, the more likely that an exception will be raised by a line of\ncode that you didn\u2019t expect to raise an exception. In those cases, the\ntry/except block hides a real error.\n\n\nUse the finally clause to execute code whether or not an exception is\nraised in the try block. This is often useful for cleanup, i.e., closing a\nfile.\n\n\n\n\n\n\n\n2.5 Mutable Global State\nAvoid mutable global state.\n\n\n\n2.5.1 Definition\nModule-level values or class attributes that can get mutated during program\nexecution.\n\n\n\n2.5.2 Pros\nOccasionally useful.\n\n\n\n2.5.3 Cons\n\n\nBreaks encapsulation: Such design can make it hard to achieve valid\nobjectives. For example, if global state is used to manage a database\nconnection, then connecting to two different databases at the same time\n(such as for computing differences during a migration) becomes difficult.\nSimilar problems easily arise with global registries.\n\n\nHas the potential to change module behavior during the import, because\nassignments to global variables are done when the module is first imported.\n\n\n\n\n\n2.5.4 Decision\nAvoid mutable global state.\nIn those rare cases where using global state is warranted, mutable global\nentities should be declared at the module level or as a class attribute and made\ninternal by prepending an _ to the name. If necessary, external access to\nmutable global state must be done through public functions or class methods. See\nNaming below. Please explain the design reasons why mutable\nglobal state is being used in a comment or a doc linked to from a comment.\nModule-level constants are permitted and encouraged. For example:\n_MAX_HOLY_HANDGRENADE_COUNT = 3 for an internal use constant or\nSIR_LANCELOTS_FAVORITE_COLOR = \"blue\" for a public API constant. Constants\nmust be named using all caps with underscores. See Naming\nbelow.\n\n\n\n2.6 Nested/Local/Inner Classes and Functions\nNested local functions or classes are fine when used to close over a local\nvariable. Inner classes are fine.\n\n\n\n2.6.1 Definition\nA class can be defined inside of a method, function, or class. A function can be\ndefined inside a method or function. Nested functions have read-only access to\nvariables defined in enclosing scopes.\n\n\n\n2.6.2 Pros\nAllows definition of utility classes and functions that are only used inside of\na very limited scope. Very\nADT-y. Commonly used for\nimplementing decorators.\n\n\n\n2.6.3 Cons\nNested functions and classes cannot be directly tested. Nesting can make the\nouter function longer and less readable.\n\n\n\n2.6.4 Decision\nThey are fine with some caveats. Avoid nested functions or classes except when\nclosing over a local value other than self or cls. Do not nest a function\njust to hide it from users of a module. Instead, prefix its name with an _ at\nthe module level so that it can still be accessed by tests.\n\n\n\n\n\n\n2.7 Comprehensions & Generator Expressions\nOkay to use for simple cases.\n\n\n\n2.7.1 Definition\nList, Dict, and Set comprehensions as well as generator expressions provide a\nconcise and efficient way to create container types and iterators without\nresorting to the use of traditional loops, map(), filter(), or lambda.\n\n\n\n2.7.2 Pros\nSimple comprehensions can be clearer and simpler than other dict, list, or set\ncreation techniques. Generator expressions can be very efficient, since they\navoid the creation of a list entirely.\n\n\n\n2.7.3 Cons\nComplicated comprehensions or generator expressions can be hard to read.\n\n\n\n2.7.4 Decision\nComprehensions are allowed, however multiple for clauses or filter expressions\nare not permitted. Optimize for readability, not conciseness.\nYes:\n  result = [mapping_expr for value in iterable if filter_expr]\n\n  result = [\n      is_valid(metric={'key': value})\n      for value in interesting_iterable\n      if a_longer_filter_expression(value)\n  ]\n\n  descriptive_name = [\n      transform({'key': key, 'value': value}, color='black')\n      for key, value in generate_iterable(some_input)\n      if complicated_condition_is_met(key, value)\n  ]\n\n  result = []\n  for x in range(10):\n    for y in range(5):\n      if x * y > 10:\n        result.append((x, y))\n\n  return {\n      x: complicated_transform(x)\n      for x in long_generator_function(parameter)\n      if x is not None\n  }\n\n  return (x**2 for x in range(10))\n\n  unique_names = {user.name for user in users if user is not None}\n\nNo:\n  result = [(x, y) for x in range(10) for y in range(5) if x * y > 10]\n\n  return (\n      (x, y, z)\n      for x in range(5)\n      for y in range(5)\n      if x != y\n      for z in range(5)\n      if y != z\n  )\n\n\n\n2.8 Default Iterators and Operators\nUse default iterators and operators for types that support them, like lists,\ndictionaries, and files.\n\n\n\n2.8.1 Definition\nContainer types, like dictionaries and lists, define default iterators and\nmembership test operators (\u201cin\u201d and \u201cnot in\u201d).\n\n\n\n2.8.2 Pros\nThe default iterators and operators are simple and efficient. They express the\noperation directly, without extra method calls. A function that uses default\noperators is generic. It can be used with any type that supports the operation.\n\n\n\n2.8.3 Cons\nYou can\u2019t tell the type of objects by reading the method names (unless the\nvariable has type annotations). This is also an advantage.\n\n\n\n2.8.4 Decision\nUse default iterators and operators for types that support them, like lists,\ndictionaries, and files. The built-in types define iterator methods, too. Prefer\nthese methods to methods that return lists, except that you should not mutate a\ncontainer while iterating over it.\nYes:  for key in adict: ...\n      if obj in alist: ...\n      for line in afile: ...\n      for k, v in adict.items(): ...\n\nNo:   for key in adict.keys(): ...\n      for line in afile.readlines(): ...\n\n\n\n\n2.9 Generators\nUse generators as needed.\n\n\n\n2.9.1 Definition\nA generator function returns an iterator that yields a value each time it\nexecutes a yield statement. After it yields a value, the runtime state of the\ngenerator function is suspended until the next value is needed.\n\n\n\n2.9.2 Pros\nSimpler code, because the state of local variables and control flow are\npreserved for each call. A generator uses less memory than a function that\ncreates an entire list of values at once.\n\n\n\n2.9.3 Cons\nLocal variables in the generator will not be garbage collected until the\ngenerator is either consumed to exhaustion or itself garbage collected.\n\n\n\n2.9.4 Decision\nFine. Use \u201cYields:\u201d rather than \u201cReturns:\u201d in the docstring for generator\nfunctions.\nIf the generator manages an expensive resource, make sure to force the clean up.\nA good way to do the clean up is by wrapping the generator with a context\nmanager PEP-0533.\n\n\n\n2.10 Lambda Functions\nOkay for one-liners. Prefer generator expressions over map() or filter()\nwith a lambda.\n\n\n\n2.10.1 Definition\nLambdas define anonymous functions in an expression, as opposed to a statement.\n\n\n\n2.10.2 Pros\nConvenient.\n\n\n\n2.10.3 Cons\nHarder to read and debug than local functions. The lack of names means stack\ntraces are more difficult to understand. Expressiveness is limited because the\nfunction may only contain an expression.\n\n\n\n2.10.4 Decision\nLambdas are allowed. If the code inside the lambda function spans multiple lines\nor is longer than 60-80 chars, it might be better to define it as a regular\nnested function.\nFor common operations like multiplication, use the functions from the operator\nmodule instead of lambda functions. For example, prefer operator.mul to\nlambda x, y: x * y.\n\n\n\n2.11 Conditional Expressions\nOkay for simple cases.\n\n\n\n2.11.1 Definition\nConditional expressions (sometimes called a \u201cternary operator\u201d) are mechanisms\nthat provide a shorter syntax for if statements. For example: x = 1 if cond\nelse 2.\n\n\n\n2.11.2 Pros\nShorter and more convenient than an if statement.\n\n\n\n2.11.3 Cons\nMay be harder to read than an if statement. The condition may be difficult to\nlocate if the expression is long.\n\n\n\n2.11.4 Decision\nOkay to use for simple cases. Each portion must fit on one line:\ntrue-expression, if-expression, else-expression. Use a complete if statement\nwhen things get more complicated.\nYes:\n    one_line = 'yes' if predicate(value) else 'no'\n    slightly_split = ('yes' if predicate(value)\n                      else 'no, nein, nyet')\n    the_longest_ternary_style_that_can_be_done = (\n        'yes, true, affirmative, confirmed, correct'\n        if predicate(value)\n        else 'no, false, negative, nay')\n\nNo:\n    bad_line_breaking = ('yes' if predicate(value) else\n                         'no')\n    portion_too_long = ('yes'\n                        if some_long_module.some_long_predicate_function(\n                            really_long_variable_name)\n                        else 'no, false, negative, nay')\n\n\n\n\n2.12 Default Argument Values\nOkay in most cases.\n\n\n\n2.12.1 Definition\nYou can specify values for variables at the end of a function\u2019s parameter list,\ne.g., def foo(a, b=0):. If foo is called with only one argument, b is set\nto 0. If it is called with two arguments, b has the value of the second\nargument.\n\n\n\n2.12.2 Pros\nOften you have a function that uses lots of default values, but on rare\noccasions you want to override the defaults. Default argument values provide an\neasy way to do this, without having to define lots of functions for the rare\nexceptions. As Python does not support overloaded methods/functions, default\narguments are an easy way of \u201cfaking\u201d the overloading behavior.\n\n\n\n2.12.3 Cons\nDefault arguments are evaluated once at module load time. This may cause\nproblems if the argument is a mutable object such as a list or a dictionary. If\nthe function modifies the object (e.g., by appending an item to a list), the\ndefault value is modified.\n\n\n\n2.12.4 Decision\nOkay to use with the following caveat:\nDo not use mutable objects as default values in the function or method\ndefinition.\nYes: def foo(a, b=None):\n         if b is None:\n             b = []\nYes: def foo(a, b: Sequence | None = None):\n         if b is None:\n             b = []\nYes: def foo(a, b: Sequence = ()):  # Empty tuple OK since tuples are immutable.\n         ...\n\nfrom absl import flags\n_FOO = flags.DEFINE_string(...)\n\nNo:  def foo(a, b=[]):\n         ...\nNo:  def foo(a, b=time.time()):  # Is `b` supposed to represent when this module was loaded?\n         ...\nNo:  def foo(a, b=_FOO.value):  # sys.argv has not yet been parsed...\n         ...\nNo:  def foo(a, b: Mapping = {}):  # Could still get passed to unchecked code.\n         ...\n\n\n\n\n2.13 Properties\nProperties may be used to control getting or setting attributes that require\ntrivial computations or logic. Property implementations must match the general\nexpectations of regular attribute access: that they are cheap, straightforward,\nand unsurprising.\n\n\n\n2.13.1 Definition\nA way to wrap method calls for getting and setting an attribute as a standard\nattribute access.\n\n\n\n2.13.2 Pros\n\nAllows for an attribute access and assignment API rather than\ngetter and setter method calls.\nCan be used to make an attribute read-only.\nAllows calculations to be lazy.\nProvides a way to maintain the public interface of a class when the\ninternals evolve independently of class users.\n\n\n\n\n2.13.3 Cons\n\nCan hide side-effects much like operator overloading.\nCan be confusing for subclasses.\n\n\n\n\n2.13.4 Decision\nProperties are allowed, but, like operator overloading, should only be used when\nnecessary and match the expectations of typical attribute access; follow the\ngetters and setters rules otherwise.\nFor example, using a property to simply both get and set an internal attribute\nisn\u2019t allowed: there is no computation occurring, so the property is unnecessary\n(make the attribute public instead). In comparison,\nusing a property to control attribute access or to calculate a trivially\nderived value is allowed: the logic is simple and unsurprising.\nProperties should be created with the @property\ndecorator. Manually implementing a\nproperty descriptor is considered a power feature.\nInheritance with properties can be non-obvious. Do not use properties to\nimplement computations a subclass may ever want to override and extend.\n\n\n\n2.14 True/False Evaluations\nUse the \u201cimplicit\u201d false if at all possible (with a few caveats).\n\n\n\n2.14.1 Definition\nPython evaluates certain values as False when in a boolean context. A quick\n\u201crule of thumb\u201d is that all \u201cempty\u201d values are considered false, so 0, None,\n[], {}, '' all evaluate as false in a boolean context.\n\n\n\n2.14.2 Pros\nConditions using Python booleans are easier to read and less error-prone. In\nmost cases, they\u2019re also faster.\n\n\n\n2.14.3 Cons\nMay look strange to C/C++ developers.\n\n\n\n2.14.4 Decision\nUse the \u201cimplicit\u201d false if possible, e.g., if foo: rather than if foo !=\n[]:. There are a few caveats that you should keep in mind though:\n\n\nAlways use if foo is None: (or is not None) to check for a None value.\nE.g., when testing whether a variable or argument that defaults to None\nwas set to some other value. The other value might be a value that\u2019s false\nin a boolean context!\n\n\nNever compare a boolean variable to False using ==. Use if not x:\ninstead. If you need to distinguish False from None then chain the\nexpressions, such as if not x and x is not None:.\n\n\nFor sequences (strings, lists, tuples), use the fact that empty sequences\nare false, so if seq: and if not seq: are preferable to if len(seq):\nand if not len(seq): respectively.\n\n\nWhen handling integers, implicit false may involve more risk than benefit\n(i.e., accidentally handling None as 0). You may compare a value which is\nknown to be an integer (and is not the result of len()) against the\ninteger 0.\nYes: if not users:\n         print('no users')\n\n     if i % 10 == 0:\n         self.handle_multiple_of_ten()\n\n     def f(x=None):\n         if x is None:\n             x = []\n \nNo:  if len(users) == 0:\n         print('no users')\n\n     if not i % 10:\n         self.handle_multiple_of_ten()\n\n     def f(x=None):\n         x = x or []\n \n\n\nNote that '0' (i.e., 0 as string) evaluates to true.\n\n\nNote that Numpy arrays may raise an exception in an implicit boolean\ncontext. Prefer the .size attribute when testing emptiness of a np.array\n(e.g. if not users.size).\n\n\n\n\n\n2.16 Lexical Scoping\nOkay to use.\n\n\n\n2.16.1 Definition\nA nested Python function can refer to variables defined in enclosing functions,\nbut cannot assign to them. Variable bindings are resolved using lexical scoping,\nthat is, based on the static program text. Any assignment to a name in a block\nwill cause Python to treat all references to that name as a local variable, even\nif the use precedes the assignment. If a global declaration occurs, the name is\ntreated as a global variable.\nAn example of the use of this feature is:\ndef get_adder(summand1: float) -> Callable[[float], float]:\n    \"\"\"Returns a function that adds numbers to a given number.\"\"\"\n    def adder(summand2: float) -> float:\n        return summand1 + summand2\n\n    return adder\n\n\n\n\n2.16.2 Pros\nOften results in clearer, more elegant code. Especially comforting to\nexperienced Lisp and Scheme (and Haskell and ML and \u2026) programmers.\n\n\n\n2.16.3 Cons\nCan lead to confusing bugs, such as this example based on\nPEP-0227:\ni = 4\ndef foo(x: Iterable[int]):\n    def bar():\n        print(i, end='')\n    # ...\n    # A bunch of code here\n    # ...\n    for i in x:  # Ah, i *is* local to foo, so this is what bar sees\n        print(i, end='')\n    bar()\n\nSo foo([1, 2, 3]) will print 1 2 3 3,\nnot 1 2 3 4.\n\n\n\n2.16.4 Decision\nOkay to use.\n\n\n\n\n2.17 Function and Method Decorators\nUse decorators judiciously when there is a clear advantage. Avoid staticmethod\nand limit use of classmethod.\n\n\n\n2.17.1 Definition\nDecorators for Functions and Methods\n(a.k.a \u201cthe @ notation\u201d). One common decorator is @property, used for\nconverting ordinary methods into dynamically computed attributes. However, the\ndecorator syntax allows for user-defined decorators as well. Specifically, for\nsome function my_decorator, this:\nclass C:\n    @my_decorator\n    def method(self):\n        # method body ...\n\nis equivalent to:\nclass C:\n    def method(self):\n        # method body ...\n    method = my_decorator(method)\n\n\n\n\n2.17.2 Pros\nElegantly specifies some transformation on a method; the transformation might\neliminate some repetitive code, enforce invariants, etc.\n\n\n\n2.17.3 Cons\nDecorators can perform arbitrary operations on a function\u2019s arguments or return\nvalues, resulting in surprising implicit behavior. Additionally, decorators\nexecute at object definition time. For module-level objects (classes, module\nfunctions, \u2026) this happens at import time. Failures in decorator code are\npretty much impossible to recover from.\n\n\n\n2.17.4 Decision\nUse decorators judiciously when there is a clear advantage. Decorators should\nfollow the same import and naming guidelines as functions. A decorator docstring\nshould clearly state that the function is a decorator. Write unit tests for\ndecorators.\nAvoid external dependencies in the decorator itself (e.g. don\u2019t rely on files,\nsockets, database connections, etc.), since they might not be available when the\ndecorator runs (at import time, perhaps from pydoc or other tools). A\ndecorator that is called with valid parameters should (as much as possible) be\nguaranteed to succeed in all cases.\nDecorators are a special case of \u201ctop-level code\u201d - see main for\nmore discussion.\nNever use staticmethod unless forced to in order to integrate with an API\ndefined in an existing library. Write a module-level function instead.\nUse classmethod only when writing a named constructor, or a class-specific\nroutine that modifies necessary global state such as a process-wide cache.\n\n\n\n2.18 Threading\nDo not rely on the atomicity of built-in types.\nWhile Python\u2019s built-in data types such as dictionaries appear to have atomic\noperations, there are corner cases where they aren\u2019t atomic (e.g. if __hash__\nor __eq__ are implemented as Python methods) and their atomicity should not be\nrelied upon. Neither should you rely on atomic variable assignment (since this\nin turn depends on dictionaries).\nUse the queue module\u2019s Queue data type as the preferred way to communicate\ndata between threads. Otherwise, use the threading module and its locking\nprimitives. Prefer condition variables and threading.Condition instead of\nusing lower-level locks.\n\n\n\n2.19 Power Features\nAvoid these features.\n\n\n\n2.19.1 Definition\nPython is an extremely flexible language and gives you many fancy features such\nas custom metaclasses, access to bytecode, on-the-fly compilation, dynamic\ninheritance, object reparenting, import hacks, reflection (e.g. some uses of\ngetattr()), modification of system internals, __del__ methods implementing\ncustomized cleanup, etc.\n\n\n\n2.19.2 Pros\nThese are powerful language features. They can make your code more compact.\n\n\n\n2.19.3 Cons\nIt\u2019s very tempting to use these \u201ccool\u201d features when they\u2019re not absolutely\nnecessary. It\u2019s harder to read, understand, and debug code that\u2019s using unusual\nfeatures underneath. It doesn\u2019t seem that way at first (to the original author),\nbut when revisiting the code, it tends to be more difficult than code that is\nlonger but is straightforward.\n\n\n\n2.19.4 Decision\nAvoid these features in your code.\nStandard library modules and classes that internally use these features are okay\nto use (for example, abc.ABCMeta, dataclasses, and enum).\n\n\n\n2.20 Modern Python: from __future__ imports\nNew language version semantic changes may be gated behind a special future\nimport to enable them on a per-file basis within earlier runtimes.\n\n\n\n2.20.1 Definition\nBeing able to turn on some of the more modern features via from __future__\nimport statements allows early use of features from expected future Python\nversions.\n\n\n\n2.20.2 Pros\nThis has proven to make runtime version upgrades smoother as changes can be made\non a per-file basis while declaring compatibility and preventing regressions\nwithin those files. Modern code is more maintainable as it is less likely to\naccumulate technical debt that will be problematic during future runtime\nupgrades.\n\n\n\n2.20.3 Cons\nSuch code may not work on very old interpreter versions prior to the\nintroduction of the needed future statement. The need for this is more common in\nprojects supporting an extremely wide variety of environments.\n\n\n\n2.20.4 Decision\nfrom __future__ imports\nUse of from __future__ import statements is encouraged. It allows a given\nsource file to start using more modern Python syntax features today. Once you no\nlonger need to run on a version where the features are hidden behind a\n__future__ import, feel free to remove those lines.\nIn code that may execute on versions as old as 3.5 rather than >= 3.7, import:\nfrom __future__ import generator_stop\n\nFor more information read the\nPython future statement definitions\ndocumentation.\nPlease don\u2019t remove these imports until you are confident the code is only ever\nused in a sufficiently modern environment. Even if you do not currently use the\nfeature a specific future import enables in your code today, keeping it in place\nin the file prevents later modifications of the code from inadvertently\ndepending on the older behavior.\nUse other from __future__ import statements as you see fit.\n\n\n\n\n\n2.21 Type Annotated Code\nYou can annotate Python code with\ntype hints. Type-check the code\nat build time with a type checking tool like pytype.\nIn most cases, when feasible, type annotations are in source files. For\nthird-party or extension modules, annotations can be in\nstub .pyi files.\n\n\n\n2.21.1 Definition\nType annotations (or \u201ctype hints\u201d) are for function or method arguments and\nreturn values:\ndef func(a: int) -> list[int]:\n\nYou can also declare the type of a variable using similar syntax:\na: SomeType = some_func()\n\n\n\n\n2.21.2 Pros\nType annotations improve the readability and maintainability of your code. The\ntype checker will convert many runtime errors to build-time errors, and reduce\nyour ability to use Power Features.\n\n\n\n2.21.3 Cons\nYou will have to keep the type declarations up to date.\nYou might see type errors that you think are\nvalid code. Use of a\ntype checker\nmay reduce your ability to use Power Features.\n\n\n\n2.21.4 Decision\nYou are strongly encouraged to enable Python type analysis when updating code.\nWhen adding or modifying public APIs, include type annotations and enable\nchecking via pytype in the build system. As static analysis is relatively new to\nPython, we acknowledge that undesired side-effects (such as\nwrongly\ninferred types) may prevent adoption by some projects. In those situations,\nauthors are encouraged to add a comment with a TODO or link to a bug describing\nthe issue(s) currently preventing type annotation adoption in the BUILD file or\nin the code itself as appropriate.\n\n\n\n3 Python Style Rules\n\n\n\n3.1 Semicolons\nDo not terminate your lines with semicolons, and do not use semicolons to put\ntwo statements on the same line.\n\n\n\n3.2 Line length\nMaximum line length is 80 characters.\nExplicit exceptions to the 80 character limit:\n\nLong import statements.\nURLs, pathnames, or long flags in comments.\nLong string module-level constants not containing whitespace that would be\ninconvenient to split across lines such as URLs or pathnames.\n    \nPylint disable comments. (e.g.: # pylint: disable=invalid-name)\n\n\n\nDo not use a backslash for\nexplicit line continuation.\nInstead, make use of Python\u2019s\nimplicit line joining inside parentheses, brackets and braces.\nIf necessary, you can add an extra pair of parentheses around an expression.\nNote that this rule doesn\u2019t prohibit backslash-escaped newlines within strings\n(see below).\nYes: foo_bar(self, width, height, color='black', design=None, x='foo',\n             emphasis=None, highlight=0)\n\n\nYes: if (width == 0 and height == 0 and\n         color == 'red' and emphasis == 'strong'):\n\n     (bridge_questions.clarification_on\n      .average_airspeed_of.unladen_swallow) = 'African or European?'\n\n     with (\n         very_long_first_expression_function() as spam,\n         very_long_second_expression_function() as beans,\n         third_thing() as eggs,\n     ):\n       place_order(eggs, beans, spam, beans)\n\n\nNo:  if width == 0 and height == 0 and \\\n         color == 'red' and emphasis == 'strong':\n\n     bridge_questions.clarification_on \\\n         .average_airspeed_of.unladen_swallow = 'African or European?'\n\n     with very_long_first_expression_function() as spam, \\\n           very_long_second_expression_function() as beans, \\\n           third_thing() as eggs:\n       place_order(eggs, beans, spam, beans)\n\nWhen a literal string won\u2019t fit on a single line, use parentheses for implicit\nline joining.\nx = ('This will build a very long long '\n     'long long long long long long string')\n\nPrefer to break lines at the highest possible syntactic level. If you must break\na line twice, break it at the same syntactic level both times.\nYes: bridgekeeper.answer(\n         name=\"Arthur\", quest=questlib.find(owner=\"Arthur\", perilous=True))\n\n     answer = (a_long_line().of_chained_methods()\n               .that_eventually_provides().an_answer())\n\n     if (\n         config is None\n         or 'editor.language' not in config\n         or config['editor.language'].use_spaces is False\n     ):\n       use_tabs()\n\nNo: bridgekeeper.answer(name=\"Arthur\", quest=questlib.find(\n        owner=\"Arthur\", perilous=True))\n\n    answer = a_long_line().of_chained_methods().that_eventually_provides(\n        ).an_answer()\n\n    if (config is None or 'editor.language' not in config or config[\n        'editor.language'].use_spaces is False):\n      use_tabs()\n\n\nWithin comments, put long URLs on their own line if necessary.\nYes:  # See details at\n      # http://www.example.com/us/developer/documentation/api/content/v2.0/csv_file_name_extension_full_specification.html\n\nNo:  # See details at\n     # http://www.example.com/us/developer/documentation/api/content/\\\n     # v2.0/csv_file_name_extension_full_specification.html\n\nMake note of the indentation of the elements in the line continuation examples\nabove; see the indentation section for explanation.\nDocstring summary lines must remain within the 80 character\nlimit.\nIn all other cases where a line exceeds 80 characters, and the\nBlack or Pyink\nauto-formatter does not help bring the line below the limit, the line is allowed\nto exceed this maximum. Authors are encouraged to manually break the line up per\nthe notes above when it is sensible.\n\n\n\n3.3 Parentheses\nUse parentheses sparingly.\nIt is fine, though not required, to use parentheses around tuples. Do not use\nthem in return statements or conditional statements unless using parentheses for\nimplied line continuation or to indicate a tuple.\nYes: if foo:\n         bar()\n     while x:\n         x = bar()\n     if x and y:\n         bar()\n     if not x:\n         bar()\n     # For a 1 item tuple the ()s are more visually obvious than the comma.\n     onesie = (foo,)\n     return foo\n     return spam, beans\n     return (spam, beans)\n     for (x, y) in dict.items(): ...\n\nNo:  if (x):\n         bar()\n     if not(x):\n         bar()\n     return (foo)\n\n\n\n\n3.4 Indentation\nIndent your code blocks with 4 spaces.\nNever use tabs. Implied line continuation should align wrapped elements\nvertically (see line length examples), or use a hanging\n4-space indent. Closing (round, square or curly) brackets can be placed at the\nend of the expression, or on separate lines, but then should be indented the\nsame as the line with the corresponding opening bracket.\nYes:   # Aligned with opening delimiter.\n       foo = long_function_name(var_one, var_two,\n                                var_three, var_four)\n       meal = (spam,\n               beans)\n\n       # Aligned with opening delimiter in a dictionary.\n       foo = {\n           'long_dictionary_key': value1 +\n                                  value2,\n           ...\n       }\n\n       # 4-space hanging indent; nothing on first line.\n       foo = long_function_name(\n           var_one, var_two, var_three,\n           var_four)\n       meal = (\n           spam,\n           beans)\n\n       # 4-space hanging indent; nothing on first line,\n       # closing parenthesis on a new line.\n       foo = long_function_name(\n           var_one, var_two, var_three,\n           var_four\n       )\n       meal = (\n           spam,\n           beans,\n       )\n\n       # 4-space hanging indent in a dictionary.\n       foo = {\n           'long_dictionary_key':\n               long_dictionary_value,\n           ...\n       }\n\nNo:    # Stuff on first line forbidden.\n       foo = long_function_name(var_one, var_two,\n           var_three, var_four)\n       meal = (spam,\n           beans)\n\n       # 2-space hanging indent forbidden.\n       foo = long_function_name(\n         var_one, var_two, var_three,\n         var_four)\n\n       # No hanging indent in a dictionary.\n       foo = {\n           'long_dictionary_key':\n           long_dictionary_value,\n           ...\n       }\n\n\n\n\n\n\n\n\n\n\n3.4.1 Trailing commas in sequences of items?\nTrailing commas in sequences of items are recommended only when the closing\ncontainer token ], ), or } does not appear on the same line as the final\nelement, as well as for tuples with a single element. The presence of a trailing\ncomma is also used as a hint to our Python code auto-formatter\nBlack or Pyink\nto direct it to auto-format the container of items to one item per line when the\n, after the final element is present.\nYes:   golomb3 = [0, 1, 3]\n       golomb4 = [\n           0,\n           1,\n           4,\n           6,\n       ]\n\nNo:    golomb4 = [\n           0,\n           1,\n           4,\n           6,]\n\n\n\n\n3.5 Blank Lines\nTwo blank lines between top-level definitions, be they function or class\ndefinitions. One blank line between method definitions and between the docstring\nof a class and the first method. No blank line following a def line. Use\nsingle blank lines as you judge appropriate within functions or methods.\nBlank lines need not be anchored to the definition. For example, related\ncomments immediately preceding function, class, and method definitions can make\nsense. Consider if your comment might be more useful as part of the docstring.\n\n\n\n3.6 Whitespace\nFollow standard typographic rules for the use of spaces around punctuation.\nNo whitespace inside parentheses, brackets or braces.\nYes: spam(ham[1], {'eggs': 2}, [])\n\nNo:  spam( ham[ 1 ], { 'eggs': 2 }, [ ] )\n\nNo whitespace before a comma, semicolon, or colon. Do use whitespace after a\ncomma, semicolon, or colon, except at the end of the line.\nYes: if x == 4:\n         print(x, y)\n     x, y = y, x\n\nNo:  if x == 4 :\n         print(x , y)\n     x , y = y , x\n\nNo whitespace before the open paren/bracket that starts an argument list,\nindexing or slicing.\nYes: spam(1)\n\nNo:  spam (1)\n\nYes: dict['key'] = list[index]\n\nNo:  dict ['key'] = list [index]\n\nNo trailing whitespace.\nSurround binary operators with a single space on either side for assignment\n(=), comparisons (==, <, >, !=, <>, <=, >=, in, not in, is, is not), and\nBooleans (and, or, not). Use your better judgment for the insertion of spaces\naround arithmetic operators (+, -, *, /, //, %, **, @).\nYes: x == 1\n\nNo:  x<1\n\nNever use spaces around = when passing keyword arguments or defining a default\nparameter value, with one exception:\nwhen a type annotation is present, do use spaces\naround the = for the default parameter value.\nYes: def complex(real, imag=0.0): return Magic(r=real, i=imag)\nYes: def complex(real, imag: float = 0.0): return Magic(r=real, i=imag)\n\nNo:  def complex(real, imag = 0.0): return Magic(r = real, i = imag)\nNo:  def complex(real, imag: float=0.0): return Magic(r = real, i = imag)\n\nDon\u2019t use spaces to vertically align tokens on consecutive lines, since it\nbecomes a maintenance burden (applies to :, #, =, etc.):\nYes:\n  foo = 1000  # comment\n  long_name = 2  # comment that should not be aligned\n\n  dictionary = {\n      'foo': 1,\n      'long_name': 2,\n  }\n\nNo:\n  foo       = 1000  # comment\n  long_name = 2     # comment that should not be aligned\n\n  dictionary = {\n      'foo'      : 1,\n      'long_name': 2,\n  }\n\n\n\n\n\n3.7 Shebang Line\nMost .py files do not need to start with a #! line. Start the main file of a\nprogram with\n#!/usr/bin/env python3 (to support virtualenvs) or #!/usr/bin/python3 per\nPEP-394.\nThis line is used by the kernel to find the Python interpreter, but is ignored by Python when importing modules. It is only necessary on a file intended to be executed directly.\n\n\n\n\n3.8 Comments and Docstrings\nBe sure to use the right style for module, function, method docstrings and\ninline comments.\n\n\n\n\n3.8.1 Docstrings\nPython uses docstrings to document code. A docstring is a string that is the\nfirst statement in a package, module, class or function. These strings can be\nextracted automatically through the __doc__ member of the object and are used\nby pydoc.\n(Try running pydoc on your module to see how it looks.) Always use the\nthree-double-quote \"\"\" format for docstrings (per\nPEP 257). A docstring should be organized\nas a summary line (one physical line not exceeding 80 characters) terminated by\na period, question mark, or exclamation point. When writing more (encouraged),\nthis must be followed by a blank line, followed by the rest of the docstring\nstarting at the same cursor position as the first quote of the first line. There\nare more formatting guidelines for docstrings below.\n\n\n\n\n3.8.2 Modules\nEvery file should contain license boilerplate. Choose the appropriate boilerplate for the license used by the project (for example, Apache 2.0, BSD, LGPL, GPL).\nFiles should start with a docstring describing the contents and usage of the\nmodule.\n\"\"\"A one-line summary of the module or program, terminated by a period.\n\nLeave one blank line.  The rest of this docstring should contain an\noverall description of the module or program.  Optionally, it may also\ncontain a brief description of exported classes and functions and/or usage\nexamples.\n\nTypical usage example:\n\n  foo = ClassFoo()\n  bar = foo.function_bar()\n\"\"\"\n\n\n\n3.8.2.1 Test modules\nModule-level docstrings for test files are not required. They should be included\nonly when there is additional information that can be provided.\nExamples include some specifics on how the test should be run, an explanation of\nan unusual setup pattern, dependency on the external environment, and so on.\n\"\"\"This blaze test uses golden files.\n\nYou can update those files by running\n`blaze run //foo/bar:foo_test -- --update_golden_files` from the `google3`\ndirectory.\n\"\"\"\n\nDocstrings that do not provide any new information should not be used.\n\"\"\"Tests for foo.bar.\"\"\"\n\n\n\n\n\n3.8.3 Functions and Methods\nIn this section, \u201cfunction\u201d means a method, function, generator, or property.\nA docstring is mandatory for every function that has one or more of the\nfollowing properties:\n\nbeing part of the public API\nnontrivial size\nnon-obvious logic\n\nA docstring should give enough information to write a call to the function\nwithout reading the function\u2019s code. The docstring should describe the\nfunction\u2019s calling syntax and its semantics, but generally not its\nimplementation details, unless those details are relevant to how the function is\nto be used. For example, a function that mutates one of its arguments as a side\neffect should note that in its docstring. Otherwise, subtle but important\ndetails of a function\u2019s implementation that are not relevant to the caller are\nbetter expressed as comments alongside the code than within the function\u2019s\ndocstring.\nThe docstring may be descriptive-style (\"\"\"Fetches rows from a Bigtable.\"\"\")\nor imperative-style (\"\"\"Fetch rows from a Bigtable.\"\"\"), but the style should\nbe consistent within a file. The docstring for a @property data descriptor\nshould use the same style as the docstring for an attribute or a\nfunction argument (\"\"\"The Bigtable path.\"\"\",\nrather than \"\"\"Returns the Bigtable path.\"\"\").\nCertain aspects of a function should be documented in special sections, listed\nbelow. Each section begins with a heading line, which ends with a colon. All\nsections other than the heading should maintain a hanging indent of two or four\nspaces (be consistent within a file). These sections can be omitted in cases\nwhere the function\u2019s name and signature are informative enough that it can be\naptly described using a one-line docstring.\n\n\nArgs:\nList each parameter by name. A description should follow the name, and be\nseparated by a colon followed by either a space or newline. If the\ndescription is too long to fit on a single 80-character line, use a hanging\nindent of 2 or 4 spaces more than the parameter name (be consistent with the\nrest of the docstrings in the file). The description should include required\ntype(s) if the code does not contain a corresponding type annotation. If a\nfunction accepts *foo (variable length argument lists) and/or **bar\n(arbitrary keyword arguments), they should be listed as *foo and **bar.\n\nReturns: (or Yields: for generators)\nDescribe the semantics of the return value, including any type information\nthat the type annotation does not provide. If the function only returns\nNone, this section is not required. It may also be omitted if the docstring\nstarts with \u201cReturn\u201d, \u201cReturns\u201d, \u201cYield\u201d, or \u201cYields\u201d (e.g. \"\"\"Returns row\nfrom Bigtable as a tuple of strings.\"\"\") and the opening sentence is\nsufficient to describe the return value. Do not imitate older \u2018NumPy style\u2019\n(example),\nwhich frequently documented a tuple return value as if it were multiple\nreturn values with individual names (never mentioning the tuple). Instead,\ndescribe such a return value as: \u201cReturns: A tuple (mat_a, mat_b), where\nmat_a is \u2026, and \u2026\u201d. The auxiliary names in the docstring need not\nnecessarily correspond to any internal names used in the function body (as\nthose are not part of the API). If the function uses yield (is a\ngenerator), the Yields: section should document the object returned by\nnext(), instead of the generator object itself that the call evaluates to.\n\nRaises:\nList all exceptions that are relevant to the interface followed by a\ndescription. Use a similar exception name + colon + space or newline and\nhanging indent style as described in Args:. You should not document\nexceptions that get raised if the API specified in the docstring is violated\n(because this would paradoxically make behavior under violation of the API\npart of the API).\n\ndef fetch_smalltable_rows(\n    table_handle: smalltable.Table,\n    keys: Sequence[bytes | str],\n    require_all_keys: bool = False,\n) -> Mapping[bytes, tuple[str, ...]]:\n    \"\"\"Fetches rows from a Smalltable.\n\n    Retrieves rows pertaining to the given keys from the Table instance\n    represented by table_handle.  String keys will be UTF-8 encoded.\n\n    Args:\n        table_handle: An open smalltable.Table instance.\n        keys: A sequence of strings representing the key of each table\n          row to fetch.  String keys will be UTF-8 encoded.\n        require_all_keys: If True only rows with values set for all keys will be\n          returned.\n\n    Returns:\n        A dict mapping keys to the corresponding table row data\n        fetched. Each row is represented as a tuple of strings. For\n        example:\n\n        {b'Serak': ('Rigel VII', 'Preparer'),\n         b'Zim': ('Irk', 'Invader'),\n         b'Lrrr': ('Omicron Persei 8', 'Emperor')}\n\n        Returned keys are always bytes.  If a key from the keys argument is\n        missing from the dictionary, then that row was not found in the\n        table (and require_all_keys must have been False).\n\n    Raises:\n        IOError: An error occurred accessing the smalltable.\n    \"\"\"\n\nSimilarly, this variation on Args: with a line break is also allowed:\ndef fetch_smalltable_rows(\n    table_handle: smalltable.Table,\n    keys: Sequence[bytes | str],\n    require_all_keys: bool = False,\n) -> Mapping[bytes, tuple[str, ...]]:\n    \"\"\"Fetches rows from a Smalltable.\n\n    Retrieves rows pertaining to the given keys from the Table instance\n    represented by table_handle.  String keys will be UTF-8 encoded.\n\n    Args:\n      table_handle:\n        An open smalltable.Table instance.\n      keys:\n        A sequence of strings representing the key of each table row to\n        fetch.  String keys will be UTF-8 encoded.\n      require_all_keys:\n        If True only rows with values set for all keys will be returned.\n\n    Returns:\n      A dict mapping keys to the corresponding table row data\n      fetched. Each row is represented as a tuple of strings. For\n      example:\n\n      {b'Serak': ('Rigel VII', 'Preparer'),\n       b'Zim': ('Irk', 'Invader'),\n       b'Lrrr': ('Omicron Persei 8', 'Emperor')}\n\n      Returned keys are always bytes.  If a key from the keys argument is\n      missing from the dictionary, then that row was not found in the\n      table (and require_all_keys must have been False).\n\n    Raises:\n      IOError: An error occurred accessing the smalltable.\n    \"\"\"\n\n\n\n3.8.3.1 Overridden Methods\nA method that overrides a method from a base class does not need a docstring if\nit is explicitly decorated with\n@override\n(from typing_extensions or typing modules), unless the overriding method\u2019s\nbehavior materially refines the base method\u2019s contract, or details need to be\nprovided (e.g., documenting additional side effects), in which case a docstring\nwith at least those differences is required on the overriding method.\nfrom typing_extensions import override\n\nclass Parent:\n  def do_something(self):\n    \"\"\"Parent method, includes docstring.\"\"\"\n\n# Child class, method annotated with override.\nclass Child(Parent):\n  @override\n  def do_something(self):\n    pass\n\n# Child class, but without @override decorator, a docstring is required.\nclass Child(Parent):\n  def do_something(self):\n    pass\n\n# Docstring is trivial, @override is sufficient to indicate that docs can be\n# found in the base class.\nclass Child(Parent):\n  @override\n  def do_something(self):\n    \"\"\"See base class.\"\"\"\n\n\n\n\n\n3.8.4 Classes\nClasses should have a docstring below the class definition describing the class.\nPublic attributes, excluding properties, should be documented\nhere in an Attributes section and follow the same formatting as a\nfunction\u2019s Args section.\nclass SampleClass:\n    \"\"\"Summary of class here.\n\n    Longer class information...\n    Longer class information...\n\n    Attributes:\n        likes_spam: A boolean indicating if we like SPAM or not.\n        eggs: An integer count of the eggs we have laid.\n    \"\"\"\n\n    def __init__(self, likes_spam: bool = False):\n        \"\"\"Initializes the instance based on spam preference.\n\n        Args:\n          likes_spam: Defines if instance exhibits this preference.\n        \"\"\"\n        self.likes_spam = likes_spam\n        self.eggs = 0\n\n    @property\n    def butter_sticks(self) -> int:\n        \"\"\"The number of butter sticks we have.\"\"\"\n\nAll class docstrings should start with a one-line summary that describes what\nthe class instance represents. This implies that subclasses of Exception\nshould also describe what the exception represents, and not the context in which\nit might occur. The class docstring should not repeat unnecessary information,\nsuch as that the class is a class.\n# Yes:\nclass CheeseShopAddress:\n  \"\"\"The address of a cheese shop.\n\n  ...\n  \"\"\"\n\nclass OutOfCheeseError(Exception):\n  \"\"\"No more cheese is available.\"\"\"\n\n# No:\nclass CheeseShopAddress:\n  \"\"\"Class that describes the address of a cheese shop.\n\n  ...\n  \"\"\"\n\nclass OutOfCheeseError(Exception):\n  \"\"\"Raised when no more cheese is available.\"\"\"\n\n\n\n\n\n\n3.8.5 Block and Inline Comments\nThe final place to have comments is in tricky parts of the code. If you\u2019re going\nto have to explain it at the next code review,\nyou should comment it now. Complicated operations get a few lines of comments\nbefore the operations commence. Non-obvious ones get comments at the end of the\nline.\n# We use a weighted dictionary search to find out where i is in\n# the array.  We extrapolate position based on the largest num\n# in the array and the array size and then do binary search to\n# get the exact number.\n\nif i & (i-1) == 0:  # True if i is 0 or a power of 2.\n\nTo improve legibility, these comments should start at least 2 spaces away from\nthe code with the comment character #, followed by at least one space before\nthe text of the comment itself.\nOn the other hand, never describe the code. Assume the person reading the code\nknows Python (though not what you\u2019re trying to do) better than you do.\n# BAD COMMENT: Now go through the b array and make sure whenever i occurs\n# the next element is i+1\n\n\n\n\n\n\n\n\n3.8.6 Punctuation, Spelling, and Grammar\nPay attention to punctuation, spelling, and grammar; it is easier to read\nwell-written comments than badly written ones.\nComments should be as readable as narrative text, with proper capitalization and\npunctuation. In many cases, complete sentences are more readable than sentence\nfragments. Shorter comments, such as comments at the end of a line of code, can\nsometimes be less formal, but you should be consistent with your style.\nAlthough it can be frustrating to have a code reviewer point out that you are\nusing a comma when you should be using a semicolon, it is very important that\nsource code maintain a high level of clarity and readability. Proper\npunctuation, spelling, and grammar help with that goal.\n\n\n\n3.10 Strings\nUse an\nf-string,\nthe % operator, or the format method for formatting strings, even when the\nparameters are all strings. Use your best judgment to decide between string\nformatting options. A single join with + is okay but do not format with +.\nYes: x = f'name: {name}; score: {n}'\n     x = '%s, %s!' % (imperative, expletive)\n     x = '{}, {}'.format(first, second)\n     x = 'name: %s; score: %d' % (name, n)\n     x = 'name: %(name)s; score: %(score)d' % {'name':name, 'score':n}\n     x = 'name: {}; score: {}'.format(name, n)\n     x = a + b\n\nNo: x = first + ', ' + second\n    x = 'name: ' + name + '; score: ' + str(n)\n\nAvoid using the + and += operators to accumulate a string within a loop. In\nsome conditions, accumulating a string with addition can lead to quadratic\nrather than linear running time. Although common accumulations of this sort may\nbe optimized on CPython, that is an implementation detail. The conditions under\nwhich an optimization applies are not easy to predict and may change. Instead,\nadd each substring to a list and ''.join the list after the loop terminates,\nor write each substring to an io.StringIO buffer. These techniques\nconsistently have amortized-linear run-time complexity.\nYes: items = ['<table>']\n     for last_name, first_name in employee_list:\n         items.append('<tr><td>%s, %s</td></tr>' % (last_name, first_name))\n     items.append('</table>')\n     employee_table = ''.join(items)\n\nNo: employee_table = '<table>'\n    for last_name, first_name in employee_list:\n        employee_table += '<tr><td>%s, %s</td></tr>' % (last_name, first_name)\n    employee_table += '</table>'\n\nBe consistent with your choice of string quote character within a file. Pick '\nor \" and stick with it. It is okay to use the other quote character on a\nstring to avoid the need to backslash-escape quote characters within the string.\nYes:\n  Python('Why are you hiding your eyes?')\n  Gollum(\"I'm scared of lint errors.\")\n  Narrator('\"Good!\" thought a happy Python reviewer.')\n\nNo:\n  Python(\"Why are you hiding your eyes?\")\n  Gollum('The lint. It burns. It burns us.')\n  Gollum(\"Always the great lint. Watching. Watching.\")\n\nPrefer \"\"\" for multi-line strings rather than '''. Projects may choose to\nuse ''' for all non-docstring multi-line strings if and only if they also use\n' for regular strings. Docstrings must use \"\"\" regardless.\nMulti-line strings do not flow with the indentation of the rest of the program.\nIf you need to avoid embedding extra space in the string, use either\nconcatenated single-line strings or a multi-line string with\ntextwrap.dedent()\nto remove the initial space on each line:\n  No:\n  long_string = \"\"\"This is pretty ugly.\nDon't do this.\n\"\"\"\n\n  Yes:\n  long_string = \"\"\"This is fine if your use case can accept\n      extraneous leading spaces.\"\"\"\n\n  Yes:\n  long_string = (\"And this is fine if you cannot accept\\n\" +\n                 \"extraneous leading spaces.\")\n\n  Yes:\n  long_string = (\"And this too is fine if you cannot accept\\n\"\n                 \"extraneous leading spaces.\")\n\n  Yes:\n  import textwrap\n\n  long_string = textwrap.dedent(\"\"\"\\\n      This is also fine, because textwrap.dedent()\n      will collapse common leading spaces in each line.\"\"\")\n\nNote that using a backslash here does not violate the prohibition against\nexplicit line continuation; in this case, the backslash is\nescaping a newline\nin a string literal.\n\n\n\n\n3.10.1 Logging\nFor logging functions that expect a pattern-string (with %-placeholders) as\ntheir first argument: Always call them with a string literal (not an f-string!)\nas their first argument with pattern-parameters as subsequent arguments. Some\nlogging implementations collect the unexpanded pattern-string as a queryable\nfield. It also prevents spending time rendering a message that no logger is\nconfigured to output.\n  Yes:\n  import tensorflow as tf\n  logger = tf.get_logger()\n  logger.info('TensorFlow Version is: %s', tf.__version__)\n\n  Yes:\n  import os\n  from absl import logging\n\n  logging.info('Current $PAGER is: %s', os.getenv('PAGER', default=''))\n\n  homedir = os.getenv('HOME')\n  if homedir is None or not os.access(homedir, os.W_OK):\n    logging.error('Cannot write to home directory, $HOME=%r', homedir)\n\n  No:\n  import os\n  from absl import logging\n\n  logging.info('Current $PAGER is:')\n  logging.info(os.getenv('PAGER', default=''))\n\n  homedir = os.getenv('HOME')\n  if homedir is None or not os.access(homedir, os.W_OK):\n    logging.error(f'Cannot write to home directory, $HOME={homedir!r}')\n\n\n\n\n\n3.10.2 Error Messages\nError messages (such as: message strings on exceptions like ValueError, or\nmessages shown to the user) should follow three guidelines:\n\n\nThe message needs to precisely match the actual error condition.\n\n\nInterpolated pieces need to always be clearly identifiable as such.\n\n\nThey should allow simple automated processing (e.g. grepping).\n\n\n  Yes:\n  if not 0 <= p <= 1:\n    raise ValueError(f'Not a probability: {p=}')\n\n  try:\n    os.rmdir(workdir)\n  except OSError as error:\n    logging.warning('Could not remove directory (reason: %r): %r',\n                    error, workdir)\n\n  No:\n  if p < 0 or p > 1:  # PROBLEM: also false for float('nan')!\n    raise ValueError(f'Not a probability: {p=}')\n\n  try:\n    os.rmdir(workdir)\n  except OSError:\n    # PROBLEM: Message makes an assumption that might not be true:\n    # Deletion might have failed for some other reason, misleading\n    # whoever has to debug this.\n    logging.warning('Directory already was deleted: %s', workdir)\n\n  try:\n    os.rmdir(workdir)\n  except OSError:\n    # PROBLEM: The message is harder to grep for than necessary, and\n    # not universally non-confusing for all possible values of `workdir`.\n    # Imagine someone calling a library function with such code\n    # using a name such as workdir = 'deleted'. The warning would read:\n    # \"The deleted directory could not be deleted.\"\n    logging.warning('The %s directory could not be deleted.', workdir)\n\n\n\n\n\n\n3.11 Files, Sockets, and similar Stateful Resources\nExplicitly close files and sockets when done with them. This rule naturally\nextends to closeable resources that internally use sockets, such as database\nconnections, and also other resources that need to be closed down in a similar\nfashion. To name only a few examples, this also includes\nmmap mappings,\nh5py File objects, and\nmatplotlib.pyplot figure windows.\nLeaving files, sockets or other such stateful objects open unnecessarily has\nmany downsides:\n\nThey may consume limited system resources, such as file descriptors. Code\nthat deals with many such objects may exhaust those resources unnecessarily\nif they\u2019re not returned to the system promptly after use.\nHolding files open may prevent other actions such as moving or deleting\nthem, or unmounting a filesystem.\nFiles and sockets that are shared throughout a program may inadvertently be\nread from or written to after logically being closed. If they are actually\nclosed, attempts to read or write from them will raise exceptions, making\nthe problem known sooner.\n\nFurthermore, while files and sockets (and some similarly behaving resources) are\nautomatically closed when the object is destructed, coupling the lifetime of the\nobject to the state of the resource is poor practice:\n\nThere are no guarantees as to when the runtime will actually invoke the\n__del__ method. Different Python implementations use different memory\nmanagement techniques, such as delayed garbage collection, which may\nincrease the object\u2019s lifetime arbitrarily and indefinitely.\nUnexpected references to the file, e.g. in globals or exception tracebacks,\nmay keep it around longer than intended.\n\nRelying on finalizers to do automatic cleanup that has observable side effects\nhas been rediscovered over and over again to lead to major problems, across many\ndecades and multiple languages (see e.g.\nthis article\nfor Java).\nThe preferred way to manage files and similar resources is using the\nwith statement:\nwith open(\"hello.txt\") as hello_file:\n    for line in hello_file:\n        print(line)\n\nFor file-like objects that do not support the with statement, use\ncontextlib.closing():\nimport contextlib\n\nwith contextlib.closing(urllib.urlopen(\"http://www.python.org/\")) as front_page:\n    for line in front_page:\n        print(line)\n\nIn rare cases where context-based resource management is infeasible, code\ndocumentation must explain clearly how resource lifetime is managed.\n\n\n\n3.12 TODO Comments\nUse TODO comments for code that is temporary, a short-term solution, or\ngood-enough but not perfect.\nA TODO comment begins with the word TODO in all caps, a following colon, and\na link to a resource that contains the context, ideally a bug reference. A bug\nreference is preferable because bugs are tracked and have follow-up comments.\nFollow this piece of context with an explanatory string introduced with a hyphen\n-. \nThe purpose is to have a consistent TODO format that can be searched to find\nout how to get more details.\n# TODO: crbug.com/192795 - Investigate cpufreq optimizations.\n\nOld style, formerly recommended, but discouraged for use in new code:\n# TODO(crbug.com/192795): Investigate cpufreq optimizations.\n# TODO(yourusername): Use a \"\\*\" here for concatenation operator.\n\nAvoid adding TODOs that refer to an individual or team as the context:\n# TODO: @yourusername - File an issue and use a '*' for repetition.\n\nIf your TODO is of the form \u201cAt a future date do something\u201d make sure that you\neither include a very specific date (\u201cFix by November 2009\u201d) or a very specific\nevent (\u201cRemove this code when all clients can handle XML responses.\u201d) that\nfuture code maintainers will comprehend. Issues are ideal for tracking this.\n\n\n\n3.13 Imports formatting\nImports should be on separate lines; there are\nexceptions for typing and collections.abc imports.\nE.g.:\nYes: from collections.abc import Mapping, Sequence\n     import os\n     import sys\n     from typing import Any, NewType\n\nNo:  import os, sys\n\nImports are always put at the top of the file, just after any module comments\nand docstrings and before module globals and constants. Imports should be\ngrouped from most generic to least generic:\n\n\nPython future import statements. For example:\nfrom __future__ import annotations\n \nSee above for more information about those.\n\n\nPython standard library imports. For example:\nimport sys\n \n\n\nthird-party module\nor package imports. For example:\nimport tensorflow as tf\n \n\n\nCode repository\nsub-package imports. For example:\nfrom otherproject.ai import mind\n \n\n\nDeprecated: application-specific imports that are part of the same\ntop-level\nsub-package as this file. For example:\nfrom myproject.backend.hgwells import time_machine\n \nYou may find older Google Python Style code doing this, but it is no longer\nrequired. New code is encouraged not to bother with this. Simply treat\napplication-specific sub-package imports the same as other sub-package\nimports.\n\n\nWithin each grouping, imports should be sorted lexicographically, ignoring case,\naccording to each module\u2019s full package path (the path in from path import\n...). Code may optionally place a blank line between import sections.\nimport collections\nimport queue\nimport sys\n\nfrom absl import app\nfrom absl import flags\nimport bs4\nimport cryptography\nimport tensorflow as tf\n\nfrom book.genres import scifi\nfrom myproject.backend import huxley\nfrom myproject.backend.hgwells import time_machine\nfrom myproject.backend.state_machine import main_loop\nfrom otherproject.ai import body\nfrom otherproject.ai import mind\nfrom otherproject.ai import soul\n\n# Older style code may have these imports down here instead:\n#from myproject.backend.hgwells import time_machine\n#from myproject.backend.state_machine import main_loop\n\n\n\n\n3.14 Statements\nGenerally only one statement per line.\nHowever, you may put the result of a test on the same line as the test only if\nthe entire statement fits on one line. In particular, you can never do so with\ntry/except since the try and except can\u2019t both fit on the same line, and\nyou can only do so with an if if there is no else.\nYes:\n\n  if foo: bar(foo)\n\nNo:\n\n  if foo: bar(foo)\n  else:   baz(foo)\n\n  try:               bar(foo)\n  except ValueError: baz(foo)\n\n  try:\n      bar(foo)\n  except ValueError: baz(foo)\n\n\n\n\n\n\n\n3.15 Getters and Setters\nGetter and setter functions (also called accessors and mutators) should be used\nwhen they provide a meaningful role or behavior for getting or setting a\nvariable\u2019s value.\nIn particular, they should be used when getting or setting the variable is\ncomplex or the cost is significant, either currently or in a reasonable future.\nIf, for example, a pair of getters/setters simply read and write an internal\nattribute, the internal attribute should be made public instead. By comparison,\nif setting a variable means some state is invalidated or rebuilt, it should be a\nsetter function. The function invocation hints that a potentially non-trivial\noperation is occurring. Alternatively, properties may be an\noption when simple logic is needed, or refactoring to no longer need getters and\nsetters.\nGetters and setters should follow the Naming guidelines, such\nas get_foo() and set_foo().\nIf the past behavior allowed access through a property, do not bind the new\ngetter/setter functions to the property. Any code still attempting to access the\nvariable by the old method should break visibly so they are made aware of the\nchange in complexity.\n\n\n\n3.16 Naming\nmodule_name, package_name, ClassName, method_name, ExceptionName,\nfunction_name, GLOBAL_CONSTANT_NAME, global_var_name, instance_var_name,\nfunction_parameter_name, local_var_name, query_proper_noun_for_thing,\nsend_acronym_via_https.\nNames should be descriptive. This includes functions, classes, variables,\nattributes, files and any other type of named entities.\nAvoid abbreviation. In particular, do not use abbreviations that are ambiguous\nor unfamiliar to readers outside your project, and do not abbreviate by deleting\nletters within a word.\nAlways use a .py filename extension. Never use dashes.\n\n\n\n3.16.1 Names to Avoid\n\n\nsingle character names, except for specifically allowed cases:\n\ncounters or iterators (e.g. i, j, k, v, et al.)\ne as an exception identifier in try/except statements.\nf as a file handle in with statements\nprivate type variables with no constraints (e.g.\n_T = TypeVar(\"_T\"), _P = ParamSpec(\"_P\"))\nnames that match established notation in a reference paper or algorithm\n(see Mathematical Notation)\n\nPlease be mindful not to abuse single-character naming. Generally speaking,\ndescriptiveness should be proportional to the name\u2019s scope of visibility.\nFor example, i might be a fine name for 5-line code block but within\nmultiple nested scopes, it is likely too vague.\n\n\ndashes (-) in any package/module name\n\n\n__double_leading_and_trailing_underscore__ names (reserved by Python)\n\n\noffensive terms\n\n\nnames that needlessly include the type of the variable (for example:\nid_to_name_dict)\n\n\n\n\n\n3.16.2 Naming Conventions\n\n\n\u201cInternal\u201d means internal to a module, or protected or private within a\nclass.\n\n\nPrepending a single underscore (_) has some support for protecting module\nvariables and functions (linters will flag protected member access). Note\nthat it is okay for unit tests to access protected constants from the\nmodules under test.\n\n\nPrepending a double underscore (__ aka \u201cdunder\u201d) to an instance variable\nor method effectively makes the variable or method private to its class\n(using name mangling); we discourage its use as it impacts readability and\ntestability, and isn\u2019t really private. Prefer a single underscore.\n\n\nPlace related classes and top-level functions together in a\nmodule.\nUnlike Java, there is no need to limit yourself to one class per module.\n\n\nUse CapWords for class names, but lower_with_under.py for module names.\nAlthough there are some old modules named CapWords.py, this is now\ndiscouraged because it\u2019s confusing when the module happens to be named after\na class. (\u201cwait \u2013 did I write import StringIO or from StringIO import\nStringIO?\u201d)\n\n\nNew unit test files follow PEP 8 compliant lower_with_under method\nnames, for example, test_<method_under_test>_<state>. For consistency(*)\nwith legacy modules that follow CapWords function names, underscores may\nappear in method names starting with test to separate logical components\nof the name. One possible pattern is test<MethodUnderTest>_<state>.\n\n\n\n\n\n3.16.3 File Naming\nPython filenames must have a .py extension and must not contain dashes (-).\nThis allows them to be imported and unittested. If you want an executable to be\naccessible without the extension, use a symbolic link or a simple bash wrapper\ncontaining exec \"$0.py\" \"$@\".\n\n\n\n3.16.4 Guidelines derived from Guido\u2019s Recommendations\n\n\nType\nPublic\nInternal\n\n\nPackages\nlower_with_under\n\n\n\nModules\nlower_with_under\n_lower_with_under\n\n\nClasses\nCapWords\n_CapWords\n\n\nExceptions\nCapWords\n\n\n\nFunctions\nlower_with_under()\n_lower_with_under()\n\n\nGlobal/Class Constants\nCAPS_WITH_UNDER\n_CAPS_WITH_UNDER\n\n\nGlobal/Class Variables\nlower_with_under\n_lower_with_under\n\n\nInstance Variables\nlower_with_under\n_lower_with_under (protected)\n\n\nMethod Names\nlower_with_under()\n_lower_with_under() (protected)\n\n\nFunction/Method Parameters\nlower_with_under\n\n\n\nLocal Variables\nlower_with_under\n\n\n\n\n\n\n3.16.5 Mathematical Notation\nFor mathematically-heavy code, short variable names that would otherwise violate\nthe style guide are preferred when they match established notation in a\nreference paper or algorithm.\nWhen using names based on established notation:\n\nCite the source of all naming conventions, preferably with a hyperlink to\nacademic resource itself, in a comment or docstring. If the source is not\naccessible, clearly document the naming conventions.\nPrefer PEP8-compliant descriptive_names for public APIs, which are much\nmore likely to be encountered out of context.\nUse a narrowly-scoped pylint: disable=invalid-name directive to silence\nwarnings. For just a few variables, use the directive as an endline comment\nfor each one; for more, apply the directive at the beginning of a block.\n\n\n3.17 Main\nIn Python, pydoc as well as unit tests require modules to be importable. If a\nfile is meant to be used as an executable, its main functionality should be in a\nmain() function, and your code should always check if __name__ == '__main__'\nbefore executing your main program, so that it is not executed when the module\nis imported.\nWhen using absl, use app.run:\nfrom absl import app\n...\n\ndef main(argv: Sequence[str]):\n    # process non-flag arguments\n    ...\n\nif __name__ == '__main__':\n    app.run(main)\n\nOtherwise, use:\ndef main():\n    ...\n\nif __name__ == '__main__':\n    main()\n\nAll code at the top level will be executed when the module is imported. Be\ncareful not to call functions, create objects, or perform other operations that\nshould not be executed when the file is being pydoced.\n\n\n\n3.18 Function length\nPrefer small and focused functions.\nWe recognize that long functions are sometimes appropriate, so no hard limit is\nplaced on function length. If a function exceeds about 40 lines, think about\nwhether it can be broken up without harming the structure of the program.\nEven if your long function works perfectly now, someone modifying it in a few\nmonths may add new behavior. This could result in bugs that are hard to find.\nKeeping your functions short and simple makes it easier for other people to read\nand modify your code.\nYou could find long and complicated functions when working with\nsome\ncode. Do not be intimidated by modifying existing code: if working with such a\nfunction proves to be difficult, you find that errors are hard to debug, or you\nwant to use a piece of it in several different contexts, consider breaking up\nthe function into smaller and more manageable pieces.\n\n\n\n3.19 Type Annotations\n\n\n\n\n3.19.1 General Rules\n\n\nFamiliarize yourself with\ntype hints.\n\n\nAnnotating self or cls is generally not necessary.\nSelf can be\nused if it is necessary for proper type information, e.g.\nfrom typing import Self\n\nclass BaseClass:\n  @classmethod\n  def create(cls) -> Self:\n    ...\n\n  def difference(self, other: Self) -> float:\n    ...\n \n\n\nSimilarly, don\u2019t feel compelled to annotate the return value of __init__\n(where None is the only valid option).\n\n\nIf any other variable or a returned type should not be expressed, use Any.\n\n\nYou are not required to annotate all the functions in a module.\n\nAt least annotate your public APIs.\nUse judgment to get to a good balance between safety and clarity on the\none hand, and flexibility on the other.\nAnnotate code that is prone to type-related errors (previous bugs or\ncomplexity).\nAnnotate code that is hard to understand.\nAnnotate code as it becomes stable from a types perspective. In many\ncases, you can annotate all the functions in mature code without losing\ntoo much flexibility.\n\n\n\n\n\n\n3.19.2 Line Breaking\nTry to follow the existing indentation rules.\nAfter annotating, many function signatures will become \u201cone parameter per line\u201d.\nTo ensure the return type is also given its own line, a comma can be placed\nafter the last parameter.\ndef my_method(\n    self,\n    first_var: int,\n    second_var: Foo,\n    third_var: Bar | None,\n) -> int:\n  ...\n\nAlways prefer breaking between variables, and not, for example, between variable\nnames and type annotations. However, if everything fits on the same line, go for\nit.\ndef my_method(self, first_var: int) -> int:\n  ...\n\nIf the combination of the function name, the last parameter, and the return type\nis too long, indent by 4 in a new line. When using line breaks, prefer putting\neach parameter and the return type on their own lines and aligning the closing\nparenthesis with the def:\nYes:\ndef my_method(\n    self,\n    other_arg: MyLongType | None,\n) -> tuple[MyLongType1, MyLongType1]:\n  ...\n\nOptionally, the return type may be put on the same line as the last parameter:\nOkay:\ndef my_method(\n    self,\n    first_var: int,\n    second_var: int) -> dict[OtherLongType, MyLongType]:\n  ...\n\npylint\nallows you to move the closing parenthesis to a new line and align with the\nopening one, but this is less readable.\nNo:\ndef my_method(self,\n              other_arg: MyLongType | None,\n             ) -> dict[OtherLongType, MyLongType]:\n  ...\n\nAs in the examples above, prefer not to break types. However, sometimes they are\ntoo long to be on a single line (try to keep sub-types unbroken).\ndef my_method(\n    self,\n    first_var: tuple[list[MyLongType1],\n                     list[MyLongType2]],\n    second_var: list[dict[\n        MyLongType3, MyLongType4]],\n) -> None:\n  ...\n\nIf a single name and type is too long, consider using an\nalias for the type. The last resort is to break after the\ncolon and indent by 4.\nYes:\ndef my_function(\n    long_variable_name:\n        long_module_name.LongTypeName,\n) -> None:\n  ...\n\nNo:\ndef my_function(\n    long_variable_name: long_module_name.\n        LongTypeName,\n) -> None:\n  ...\n\n\n\n\n3.19.3 Forward Declarations\nIf you need to use a class name (from the same module) that is not yet\ndefined \u2013 for example, if you need the class name inside the declaration of\nthat class, or if you use a class that is defined later in the code \u2013 either\nuse from __future__ import annotations or use a string for the class name.\nYes:\nfrom __future__ import annotations\n\nclass MyClass:\n  def __init__(self, stack: Sequence[MyClass], item: OtherClass) -> None:\n\nclass OtherClass:\n  ...\n\nYes:\nclass MyClass:\n  def __init__(self, stack: Sequence['MyClass'], item: 'OtherClass') -> None:\n\nclass OtherClass:\n  ...\n\n\n\n\n3.19.4 Default Values\nAs per PEP-008, use\nspaces around the = only for arguments that have both a type annotation and\na default value.\nYes:\ndef func(a: int = 0) -> int:\n  ...\n\nNo:\ndef func(a:int=0) -> int:\n  ...\n\n\n\n\n\n3.19.5 NoneType\nIn the Python type system, NoneType is a \u201cfirst class\u201d type, and for typing\npurposes, None is an alias for NoneType. If an argument can be None, it\nhas to be declared! You can use | union type expressions (recommended in new\nPython 3.10+ code), or the older Optional and Union syntaxes.\nUse explicit X | None instead of implicit. Earlier versions of type checkers\nallowed a: str = None to be interpreted as a: str | None = None, but that is\nno longer the preferred behavior.\nYes:\ndef modern_or_union(a: str | int | None, b: str | None = None) -> str:\n  ...\ndef union_optional(a: Union[str, int, None], b: Optional[str] = None) -> str:\n  ...\n\nNo:\ndef nullable_union(a: Union[None, str]) -> str:\n  ...\ndef implicit_optional(a: str = None) -> str:\n  ...\n\n\n\n\n\n\n3.19.6 Type Aliases\nYou can declare aliases of complex types. The name of an alias should be\nCapWorded. If the alias is used only in this module, it should be _Private.\nNote that the : TypeAlias annotation is only supported in versions 3.10+.\nfrom typing import TypeAlias\n\n_LossAndGradient: TypeAlias = tuple[tf.Tensor, tf.Tensor]\nComplexTFMap: TypeAlias = Mapping[str, _LossAndGradient]\n\n\n\n\n\n3.19.7 Ignoring Types\nYou can disable type checking on a line with the special comment # type:\nignore.\npytype has a disable option for specific errors (similar to lint):\n# pytype: disable=attribute-error\n\n\n\n\n\n3.19.8 Typing Variables\n\n\nAnnotated Assignments\nIf an internal variable has a type that is hard or impossible to infer,\nspecify its type with an annotated assignment - use a colon and type between\nthe variable name and value (the same as is done with function arguments\nthat have a default value):\n\n    a: Foo = SomeUndecoratedFunction()\n \n\n\nType Comments\nThough you may see them remaining in the codebase (they were necessary\nbefore Python 3.6), do not add any more uses of a # type: <type name>\ncomment on the end of the line:\n\n    a = SomeUndecoratedFunction()  # type: Foo\n \n\n\n\n\n\n\n3.19.9 Tuples vs Lists\nTyped lists can only contain objects of a single type. Typed tuples can either\nhave a single repeated type or a set number of elements with different types.\nThe latter is commonly used as the return type from a function.\na: list[int] = [1, 2, 3]\nb: tuple[int, ...] = (1, 2, 3)\nc: tuple[int, str, float] = (1, \"2\", 3.5)\n\n\n\n\n\n\n3.19.10 Type variables\nThe Python type system has\ngenerics. A type\nvariable, such as TypeVar and ParamSpec, is a common way to use them.\nExample:\nfrom collections.abc import Callable\nfrom typing import ParamSpec, TypeVar\n_P = ParamSpec(\"_P\")\n_T = TypeVar(\"_T\")\n...\ndef next(l: list[_T]) -> _T:\n  return l.pop()\n\ndef print_when_called(f: Callable[_P, _T]) -> Callable[_P, _T]:\n  def inner(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n    print(\"Function was called\")\n    return f(*args, **kwargs)\n  return inner\n\nA TypeVar can be constrained:\nAddableType = TypeVar(\"AddableType\", int, float, str)\ndef add(a: AddableType, b: AddableType) -> AddableType:\n  return a + b\n\nA common predefined type variable in the typing module is AnyStr. Use it for\nmultiple annotations that can be bytes or str and must all be the same type.\nfrom typing import AnyStr\ndef check_length(x: AnyStr) -> AnyStr:\n  if len(x) <= 42:\n    return x\n  raise ValueError()\n\nA type variable must have a descriptive name, unless it meets all of the\nfollowing criteria:\n\nnot externally visible\nnot constrained\n\nYes:\n  _T = TypeVar(\"_T\")\n  _P = ParamSpec(\"_P\")\n  AddableType = TypeVar(\"AddableType\", int, float, str)\n  AnyFunction = TypeVar(\"AnyFunction\", bound=Callable)\n\nNo:\n  T = TypeVar(\"T\")\n  P = ParamSpec(\"P\")\n  _T = TypeVar(\"_T\", int, float, str)\n  _F = TypeVar(\"_F\", bound=Callable)\n\n\n\n\n\n3.19.11 String types\n\nDo not use typing.Text in new code. It\u2019s only for Python 2/3 compatibility.\n\nUse str for string/text data. For code that deals with binary data, use\nbytes.\ndef deals_with_text_data(x: str) -> str:\n  ...\ndef deals_with_binary_data(x: bytes) -> bytes:\n  ...\n\nIf all the string types of a function are always the same, for example if the\nreturn type is the same as the argument type in the code above, use\nAnyStr.\n\n\n\n\n3.19.12 Imports For Typing\nFor symbols (including types, functions, and constants) from the typing or\ncollections.abc modules used to support static analysis and type checking,\nalways import the symbol itself. This keeps common annotations more concise and\nmatches typing practices used around the world. You are explicitly allowed to\nimport multiple specific symbols on one line from the typing and\ncollections.abc modules. For example:\nfrom collections.abc import Mapping, Sequence\nfrom typing import Any, Generic, cast, TYPE_CHECKING\n\nGiven that this way of importing adds items to the local namespace, names in\ntyping or collections.abc should be treated similarly to keywords, and not\nbe defined in your Python code, typed or not. If there is a collision between a\ntype and an existing name in a module, import it using import x as y.\nfrom typing import Any as AnyType\n\nWhen annotating function signatures, prefer abstract container types like\ncollections.abc.Sequence over concrete types like list. If you need to use a\nconcrete type (for example, a tuple of typed elements), prefer built-in types\nlike tuple over the parametric type aliases from the typing module (e.g.,\ntyping.Tuple).\nfrom typing import List, Tuple\n\ndef transform_coordinates(original: List[Tuple[float, float]]) ->\n    List[Tuple[float, float]]:\n  ...\n\nfrom collections.abc import Sequence\n\ndef transform_coordinates(original: Sequence[tuple[float, float]]) ->\n    Sequence[tuple[float, float]]:\n  ...\n\n\n\n\n3.19.13 Conditional Imports\nUse conditional imports only in exceptional cases where the additional imports\nneeded for type checking must be avoided at runtime. This pattern is\ndiscouraged; alternatives such as refactoring the code to allow top-level\nimports should be preferred.\nImports that are needed only for type annotations can be placed within an if\nTYPE_CHECKING: block.\n\nConditionally imported types need to be referenced as strings, to be forward\ncompatible with Python 3.6 where the annotation expressions are actually\nevaluated.\nOnly entities that are used solely for typing should be defined here; this\nincludes aliases. Otherwise it will be a runtime error, as the module will\nnot be imported at runtime.\nThe block should be right after all the normal imports.\nThere should be no empty lines in the typing imports list.\nSort this list as if it were a regular imports list.\n    import typing\nif typing.TYPE_CHECKING:\n  import sketch\ndef f(x: \"sketch.Sketch\"): ...\n \n\n\n\n\n\n\n3.19.14 Circular Dependencies\nCircular dependencies that are caused by typing are code smells. Such code is a\ngood candidate for refactoring. Although technically it is possible to keep\ncircular dependencies, various build systems will not let you do so\nbecause each module has to depend on the other.\nReplace modules that create circular dependency imports with Any. Set an\nalias with a meaningful name, and use the real type name from\nthis module (any attribute of Any is Any). Alias definitions should be\nseparated from the last import by one line.\nfrom typing import Any\n\nsome_mod = Any  # some_mod.py imports this module.\n...\n\ndef my_method(self, var: \"some_mod.SomeType\") -> None:\n  ...\n\n\n\n\n\n3.19.15 Generics\nWhen annotating, prefer to specify type parameters for\ngeneric types in a\nparameter list; otherwise, the generics\u2019 parameters will be assumed to be\nAny.\n# Yes:\ndef get_names(employee_ids: Sequence[int]) -> Mapping[int, str]:\n  ...\n\n# No:\n# This is interpreted as get_names(employee_ids: Sequence[Any]) -> Mapping[Any, Any]\ndef get_names(employee_ids: Sequence) -> Mapping:\n  ...\n\nIf the best type parameter for a generic is Any, make it explicit, but\nremember that in many cases TypeVar might be more\nappropriate:\n# No:\ndef get_names(employee_ids: Sequence[Any]) -> Mapping[Any, str]:\n  \"\"\"Returns a mapping from employee ID to employee name for given IDs.\"\"\"\n\n# Yes:\n_T = TypeVar('_T')\ndef get_names(employee_ids: Sequence[_T]) -> Mapping[_T, str]:\n  \"\"\"Returns a mapping from employee ID to employee name for given IDs.\"\"\"\n\n\n\n4 Parting Words\nBE CONSISTENT.\nIf you\u2019re editing code, take a few minutes to look at the code around you and\ndetermine its style. If they use _idx suffixes in index variable names, you\nshould too. If their comments have little boxes of hash marks around them, make\nyour comments have little boxes of hash marks around them too.\nThe point of having style guidelines is to have a common vocabulary of coding so\npeople can concentrate on what you\u2019re saying rather than on how you\u2019re saying\nit. We present global style rules here so people know the vocabulary, but local\nstyle is also important. If code you add to a file looks drastically different\nfrom the existing code around it, it throws readers out of their rhythm when\nthey go to read it.\nHowever, there are limits to consistency. It applies more heavily locally and on\nchoices unspecified by the global style. Consistency should not generally be\nused as a justification to do things in an old style without considering the\nbenefits of the new style, or the tendency of the codebase to converge on newer\nstyles over time.\n\n        This site is open source. Improve this page.\n      \n\n\n\n\n\n",
    "metadata": {
      "source": "https://google.github.io/styleguide/pyguide.html",
      "title": "styleguide | Style guides for Google-originated open-source projects",
      "description": "Style guides for Google-originated open-source projects",
      "language": "en-US"
    }
  }
]